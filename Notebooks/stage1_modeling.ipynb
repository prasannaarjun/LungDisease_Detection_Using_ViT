{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T05:33:11.930621Z",
     "start_time": "2025-04-14T05:33:08.084124Z"
    }
   },
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())   # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should show RTX 4060\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:38:56.513360Z",
     "start_time": "2025-04-14T05:38:54.538605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Standard image transforms for ViT\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Single channel X-rays, normalized\n",
    "])\n",
    "\n",
    "# Paths to Stage 1 data\n",
    "stage1_base = \"../Dataset/stage1\"\n",
    "\n",
    "# Load datasets\n",
    "train_ds1 = datasets.ImageFolder(f\"{stage1_base}/train\", transform=transform)\n",
    "val_ds1 = datasets.ImageFolder(f\"{stage1_base}/val\", transform=transform)\n",
    "test_ds1 = datasets.ImageFolder(f\"{stage1_base}/test\", transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader1 = DataLoader(train_ds1, batch_size=32, shuffle=True)\n",
    "val_loader1 = DataLoader(val_ds1, batch_size=32, shuffle=False)\n",
    "test_loader1 = DataLoader(test_ds1, batch_size=32, shuffle=False)\n",
    "\n",
    "# Class mapping\n",
    "print(\"Stage 1 Classes:\", train_ds1.classes)\n"
   ],
   "id": "ff27c765ed262450",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Classes: ['Corona Virus Disease', 'Normal', 'Pneumonia', 'Tuberculosis']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:46:16.362102Z",
     "start_time": "2025-04-14T05:46:15.551789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "# Load pretrained ViT and customize for 4 classes\n",
    "model1 = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k',\n",
    "    num_labels=4\n",
    ")\n",
    "\n",
    "# Move to GPU if available\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model1.to(device)\n",
    "\n",
    "# Check architecture summary\n",
    "print(model1)\n"
   ],
   "id": "2bb500d509cb4650",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViTForImageClassification(\n",
      "  (vit): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:34:10.322711Z",
     "start_time": "2025-04-14T05:59:45.697745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 15  # Max number of epochs before early stopping\n",
    "lr = 2e-5\n",
    "patience = 3  # Number of epochs with no improvement to wait before stopping\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model1.parameters(), lr=lr)\n",
    "\n",
    "# Early stopping variables\n",
    "best_val_loss = np.inf\n",
    "epochs_without_improvement = 0\n",
    "best_model_path = \"../Model/best_model_stage1.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader1, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Training loop\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader1)\n",
    "    print(f\"Epoch {epoch+1} finished. Avg Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model1.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader1:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model1(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader1)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset patience counter\n",
    "        # Save the best model\n",
    "        torch.save(model1.state_dict(), best_model_path)\n",
    "        print(f\"Best model saved at epoch {epoch+1}.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Stop early if no improvement for `patience` epochs\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n"
   ],
   "id": "a5697774fb831cce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 190/190 [04:01<00:00,  1.27s/it, loss=0.0212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Avg Train Loss: 0.0625\n",
      "Validation Loss: 0.0983, Accuracy: 96.97%\n",
      "Best model saved at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 190/190 [04:09<00:00,  1.31s/it, loss=0.0147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished. Avg Train Loss: 0.0365\n",
      "Validation Loss: 0.1484, Accuracy: 95.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 190/190 [04:02<00:00,  1.27s/it, loss=0.0143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished. Avg Train Loss: 0.0341\n",
      "Validation Loss: 0.0873, Accuracy: 97.47%\n",
      "Best model saved at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 190/190 [03:49<00:00,  1.21s/it, loss=0.00791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished. Avg Train Loss: 0.0173\n",
      "Validation Loss: 0.0800, Accuracy: 97.92%\n",
      "Best model saved at epoch 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 190/190 [03:40<00:00,  1.16s/it, loss=0.00623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished. Avg Train Loss: 0.0188\n",
      "Validation Loss: 0.0838, Accuracy: 97.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 190/190 [04:04<00:00,  1.29s/it, loss=0.00535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 finished. Avg Train Loss: 0.0068\n",
      "Validation Loss: 0.0919, Accuracy: 97.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 190/190 [04:06<00:00,  1.30s/it, loss=0.00439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 finished. Avg Train Loss: 0.0219\n",
      "Validation Loss: 0.1299, Accuracy: 96.48%\n",
      "Early stopping triggered after 7 epochs.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:45:11.007042Z",
     "start_time": "2025-04-14T06:44:27.679473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load best model\n",
    "model1.load_state_dict(torch.load(\"../Model/best_model_stage1.pth\",weights_only=True))\n",
    "model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader1:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model1(images).logits\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"✅ Final Test Accuracy (Stage 1): {test_accuracy:.2f}%\")\n"
   ],
   "id": "eba73658fbe12c4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Test Accuracy (Stage 1): 97.88%\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
